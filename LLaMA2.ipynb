{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6c6a58-113c-43aa-9593-accdd02c2893",
   "metadata": {},
   "source": [
    "# 动⼿实现⼀个 LLaMA2 ⼤模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de772b8c-6c15-4ff6-b2ef-0fe80e8be244",
   "metadata": {},
   "source": [
    "## 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e49462e-46ab-441c-b52b-825c7aebf661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python位数：64bit\n",
      "Python路径：D:\\python\\py310\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# 在Python终端/Jupyter中执行以下代码，查看Python位数\n",
    "import platform\n",
    "import sys\n",
    "print(f\"Python位数：{platform.architecture()[0]}\")  # 必须输出64bit\n",
    "print(f\"Python路径：{sys.executable}\")  # 确认是d:\\python\\py310\\python.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48372e4-2996-4e84-b347-7928e2adc195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前Jupyter内核的Python路径： D:\\python\\py310\\python.exe\n",
      "当前内核的site-packages路径： ['D:\\\\python\\\\py310\\\\python310.zip', 'D:\\\\python\\\\py310\\\\DLLs', 'D:\\\\python\\\\py310\\\\lib', 'D:\\\\python\\\\py310', '', 'C:\\\\Users\\\\xuexu\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages', 'D:\\\\python\\\\py310\\\\lib\\\\site-packages', 'D:\\\\python\\\\py310\\\\lib\\\\site-packages\\\\win32', 'D:\\\\python\\\\py310\\\\lib\\\\site-packages\\\\win32\\\\lib', 'D:\\\\python\\\\py310\\\\lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# 输出当前内核使用的Python可执行文件路径\n",
    "print(\"当前Jupyter内核的Python路径：\", sys.executable)\n",
    "# 输出当前内核的site-packages路径（模块安装目录）\n",
    "print(\"当前内核的site-packages路径：\", sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc676c0-781b-4dac-9fa3-5642298f7709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch==2.2.0+cpu torchvision==0.17.0+cpu --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc822c7d-7f56-4bf5-b9ef-b68520127513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexu\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from transformers import PretrainedConfig, PreTrainedModel\n",
    "from typing import Optional, Tuple, Iterable, Any\n",
    "import math\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from unittest.mock import MagicMock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6722a5-2c13-4729-837a-5cc951010ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "\n",
    "class ModelConfig(PretrainedConfig):\n",
    "    model_type = \"Tiny-K\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int = 768,#模型维度\n",
    "        n_layers: int = 12, #Transformer的层数\n",
    "        n_heads: int = 16, #注意力机制的头数\n",
    "        n_kv_heads: int = 8,#键/值 头的数量\n",
    "        vocab_size: int = 6144,#词汇表大小\n",
    "        hidden_dim: int = None,#隐藏层维度;每个注意力头的特征维度\n",
    "        multiple_of: int = 64,#调整模型中间层维度的参数，核心作用是确保某些层的维度（通常是前馈网络的隐藏层维度）是 multiple_of 的整数倍\n",
    "        norm_eps:float = 1e-5,#归一化层的eps\n",
    "        max_seq_len: int =512,#输入序列的最大长度\n",
    "        dropout: float =0.0,#dropout概率\n",
    "        flash_attn:bool =True,#是否使用Flash attention\n",
    "        **kwargs,\n",
    "    \n",
    "    ):\n",
    "        self.dim = dim\n",
    "        self.n_layers =n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.n_kv_heads = n_kv_heads\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.multiple_of = multiple_of\n",
    "        self.norm_eps = norm_eps\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dropout = dropout\n",
    "        self.flash_attn = flash_attn\n",
    "        super().__init__(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b99ee7-dc85-40e4-bd46-a2e6b5d1ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35447bc-0530-41b6-97ce-bcb31caf310f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig {\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.0,\n",
       "  \"flash_attn\": true,\n",
       "  \"hidden_dim\": null,\n",
       "  \"max_seq_len\": 512,\n",
       "  \"model_type\": \"Tiny-K\",\n",
       "  \"multiple_of\": 64,\n",
       "  \"n_heads\": 16,\n",
       "  \"n_kv_heads\": 8,\n",
       "  \"n_layers\": 12,\n",
       "  \"norm_eps\": 1e-05,\n",
       "  \"transformers_version\": \"4.57.3\",\n",
       "  \"vocab_size\": 6144\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d4b0b-1797-476c-8aca-022058ca8303",
   "metadata": {},
   "source": [
    "##  构建 RMSNorm  归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7125134c-aea0-4ea8-81ee-b340d56ed6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###公式：output = (x / sqrt(mean(x²) + eps)) * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a025eb0-53bf-450e-8865-6363027c2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim:int ,eps:float):\n",
    "        super().__init__()\n",
    "        self.eps = eps #防止归一化时候分母为0\n",
    "        self.weight = nn.Parameter(torch.ones(dim))#缩放参数，可学习参数、初始化为1\n",
    "        \n",
    "    def _norm(self,x):\n",
    "        return x*torch.rsqrt(x.pow(2).mean(-1,keepdim = True) + self.eps)\n",
    "        \n",
    "    def forward(self,x):#前向传播\n",
    "        output = self._norm(x.float()).type_as(x)#首先将输入x转为float类型，然后进行RMSNorm，最后再转回原来的数据类型\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda44ab4-c799-4549-9358-b6e4998fcaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 768])\n"
     ]
    }
   ],
   "source": [
    "###测试RMSNorm\n",
    "norm = RMSNorm(args.dim, args.norm_eps)\n",
    "x = torch.randn(1, 50, args.dim)\n",
    "output = norm(x)\n",
    "print(output.shape)\n",
    "\n",
    "#out: torch.Size([1, 50, 768])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c26594-141b-4e60-b5db-653e9ce6e797",
   "metadata": {},
   "source": [
    "## 构建 LLaMA2 Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8641b4e-9bcd-45c8-90c0-47bd099c9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将键和值的维度扩展到和查询的维度⼀样\n",
    "def repeat_kv(x:torch.Tensor , n_rep:int ) -> torch.Tensor:#函数返回值类型注解（也叫类型提示 / Type Hint），->是用来标记函数返回值的类型信息的符号，目的是告诉开发者（和 IDE、静态检查工具）这个函数执行后会返回什么类型的数据。\n",
    "    bs,slen,n_kv_heads,head_dim = x.shape   # 获取输⼊张量的形状：批量⼤⼩、序列⻓度、键/值对头的数量、每个头的维度⼤⼩\n",
    "    if n_rep == 1: # 如果重复次数为1，则不需要重复，直接返回原始张量；每个 K/V 头需要复制的次数（比如 8 个 Q 头 ÷ 2 个 K/V 头 = 4 次，即n_rep=4）\n",
    "        return x \n",
    "    return (\n",
    "        x[:,:,:,None,:]#在第三个维度（即键/值对头的维度）之后添加⼀个新的维度，形成 x[:, :, :, None, :]\n",
    "        .expand(bs,slen,n_kv_heads,n_rep,head_dim)#使⽤ expand ⽅法将新添加的维度扩展到 n_rep ⼤⼩，实现键/值对的重复效果\n",
    "        .reshape(bs,slen,n_kv_heads*n_rep,head_dim)#通过 reshape ⽅法重新塑形，将扩展后的维度合并回键/值对头的数量中，即 x.reshape(bs, slen, n_kv_heads * n_rep, head_dim) ，这样最终的张量形状就达到了与查询维度⼀致的效果。\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fcc5c7b-b8df-43fb-9783-7512a59d714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 旋转嵌⼊---为注意⼒机制提供更强的上下⽂信息\n",
    "# 注意：此处的dim应为 dim//n_head，因为我们是对每个head进⾏旋转嵌⼊\n",
    "def precompute_freqs_cis(dim:int ,end:int ,theta:float=10000.0):\n",
    "    freqs = 1.0/(theta**( torch.arange(0,dim,2)[:(dim//2)].float()/dim)) #频率值\n",
    "    t = torch.arange(end,device = freqs.device)#创建的序列张量[0,1,2,...,end-1]，要和freqs张量放在同一个硬件设备上\n",
    "    freqs = torch.outer(t,freqs).float()#位置 × 频率的角度矩阵,;计算外积，得到⼀个⼆维矩阵，每⼀⾏是t的元素乘以freqs的元素\n",
    "    #每个值对应该位置、该维度对的 cos/sin 值\n",
    "    freqs_cos = torch.cos(freqs)#旋转嵌入的实部\n",
    "    freqs_sin = torch.sin(freqs)#旋转嵌入的虚部\n",
    "    \n",
    "    return freqs_cos,freqs_sin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eecf210b-a653-40eb-90f4-b3e79140b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#调整张量形状---是调整 freqs_cis 的形状，使其在进⾏⼴播操作时与 x 的维度对⻬，从⽽能够进⾏正确的张量运算\n",
    "# freqs_cis[序列长度--x个 token，每个注意力头的维度]\n",
    "#x[批量大小，序列长度，注意力头数---ndim，头维度]\n",
    "def reshape_for_broadcast(freqs_cis:torch.Tensor,x:torch.Tensor):\n",
    "    ndim = x.ndim# 获取x的维度数----注意力头数\n",
    "    assert 0<=1<=ndim# 断⾔，确保 x 有第二维\n",
    "    assert freqs_cis.shape == (x.shape[1],x.shape[-1])# 断⾔，确保freqs_cis的形状与x的第⼆维（序列长度）和最后⼀维（每个注意力头的维度）相同\n",
    "    shape = [d if i==1 or i==ndim-1 else 1 for i ,d in enumerate(x.shape)]# 构造⼀个新的形状，除了第⼆维（序列长度）和最后⼀维（每个注意力头的维度），其他维度都为1，这样做是为了能够将freqs_cis与x进⾏⼴播操作\n",
    "    return freqs_cis.view(shape)# 将freqs_cis调整为新的形状，并返回\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e33c69-d624-4eb3-994b-dd300ad45d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "###旋转嵌入\n",
    "def apply_rotary_emb(\n",
    "    xq:torch.Tensor,\n",
    "    xk:torch.Tensor,\n",
    "    freqs_cos:torch.Tensor,\n",
    "    freqs_sin:torch.Tensor\n",
    ")->Tuple[torch.Tensor,torch.Tensor]:\n",
    "    # 将查询和键张量转换为浮点数，并重塑形状以分离实部和虚部\n",
    "    xq_r,xq_i = xq.float().reshape(xq.shape[:-1]+(-1,2)).unbind(-1)\n",
    "    xk_r,xk_i = xk.float().reshape(xk.shape[:-1]+(-1,2)).unbind(-1)\n",
    "    # 重新塑形频率张量以进⾏⼴播\n",
    "    freqs_cos = reshape_for_broadcast(freqs_cos,xq_r)\n",
    "    freqs_sin = reshape_for_broadcast(freqs_sin,xq_r)\n",
    "    # 应⽤旋转，分别计算旋转后的实部和虚部\n",
    "    # 旋转公式：z' = z * (cosθ + i sinθ) → 实部= r*cos - i*sin，虚部= r*sin + i*cos\n",
    "    xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin\n",
    "    xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos\n",
    "    xk_out_r = xk_r * freqs_cos - xk_i * freqs_sin\n",
    "    xk_out_i = xk_r * freqs_sin + xk_i * freqs_cos\n",
    "    # 将最后两个维度合并，并还原为原始张量的形状\n",
    "    xq_out = torch.stack([xq_out_r,xq_out_i],dim = -1).flatten(3)\n",
    "    xk_out = torch.stack([xk_out_r,xk_out_i],dim = -1).flatten(3)\n",
    "    # 还原为原始张量的数据类型（比如从float32转回float16）\n",
    "    return xq_out.type_as(xq),xk_out.type_as(xk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57ad38c2-2904-4c07-9539-703d4a99ca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 24]) torch.Size([50, 24])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 6, 48]), torch.Size([1, 50, 6, 48]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq = torch.randn(1, 50, 6, 48) # bs, seq_len, dim//n_head, n_head_dim\n",
    "xk = torch.randn(1, 50, 6, 48) # bs, seq_len, dim//n_head, n_head_dim\n",
    "\n",
    "# 使用 precompute_freqs_cis 函数获取 sin和cos\n",
    "cos, sin = precompute_freqs_cis(288//6, 50)\n",
    "print(cos.shape, sin.shape)\n",
    "xq_out, xk_out = apply_rotary_emb(xq, xk, cos, sin)\n",
    "\n",
    "xq_out.shape, xk_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2958ef7-c6e7-4028-bdc2-552b0a19c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#组装LLaMA2 Attention\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,args:ModelConfig):\n",
    "        super().__init__()\n",
    "        # 根据是否指定n_kv_heads，确定⽤于键（key）和值（value）的头的数量。\n",
    "        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n",
    "        # 确保总头数可以被键值头数整除\n",
    "        assert args.n_heads % self.n_kv_heads == 0\n",
    "        # 模型并⾏处理⼤⼩，默认为1。\n",
    "        model_parallel_size = 1\n",
    "        # 本地计算头数，等于总头数除以模型并⾏处理⼤⼩。\n",
    "        self.n_local_heads = args.n_heads // model_parallel_size\n",
    "        # 本地键值头数，等于键值头数除以模型并⾏处理⼤⼩。\n",
    "        self.n_local_kv_heads = args.n_kv_heads // model_parallel_size\n",
    "        # 重复次数，⽤于扩展键和值的尺⼨。\n",
    "        self.n_rep = self.n_local_heads // self.n_local_kv_heads\n",
    "         # 每个头的维度，等于模型维度除以头的总数。\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        \n",
    "         # 定义权重矩阵。\n",
    "        self.wq = nn.Linear(args.dim,args.n_heads * self.head_dim ,bias =False)\n",
    "        self.wk = nn.Linear(args.dim,self.n_kv_heads * self.head_dim,bias = False)\n",
    "        self.wv = nn.Linear(args.dim,self.n_kv_heads * self.head_dim,bias = False)\n",
    "         # 输出权重矩阵。\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim ,args.dim ,bias = False)\n",
    "        # 定义dropout。\n",
    "        self.attn_dropout = nn.Dropout(args.dropout)\n",
    "        self.resid_dropout = nn.Dropout(args.dropout)\n",
    "        # 保存dropout概率。\n",
    "        self.dropout =  args.dropout\n",
    "         # 检查是否使⽤Flash Attention（需要PyTorch >= 2.0）。\n",
    "        self.flash = hasattr(torch.nn.functional,'scaled_dot_product_attention')\n",
    "        if not self.flash : # 若不⽀持Flash Attention，则使⽤⼿动实现的注意⼒机制，并设置mask。\n",
    "            print(\"WARNING : using slow attention. Flash Attention requires PyTorch >= 2.0 \")\n",
    "             # 创建⼀个上三⻆矩阵，⽤于遮蔽未来信息。\n",
    "            mask = torch.full((1,1,args.max_seq_len,args.max_seq_len),float(\"-inf\"))\n",
    "            mask = torch.triu(mask,diagonal=1)\n",
    "            # 注册为模型的缓冲区\n",
    "            self.register_buffer(\"mask\",mask)\n",
    "    def forward(self, x:torch.Tensor,freqs_cos:torch.Tensor,freqs_sin:torch):\n",
    "          # 获取批次⼤⼩和序列⻓度，[batch_size, seq_len, dim]\n",
    "        bsz,seqlen,_ = x.shape\n",
    "         # 计算查询（Q）、键（K）、值（V）\n",
    "        xq,xk,xv = self.wq(x),self.wk(x),self.wv(x)\n",
    "         # 调整形状以适应头的维度。\n",
    "        xq = xq.view(bsz,seqlen,self.n_local_heads,self.head_dim)\n",
    "        xk = xk.view(bsz,seqlen,self.n_local_kv_heads,self.head_dim)\n",
    "        xv = xv.view(bsz,seqlen,self.n_local_kv_heads,self.head_dim)\n",
    "        # 应⽤旋转位置嵌⼊（RoPE）\n",
    "        xq,xk = apply_rotary_emb(xq,xk,freqs_cos,freqs_sin)\n",
    "         # 对键和值进⾏扩展以适应重复次数。\n",
    "        xk = repeat_kv(xk,self.n_rep)\n",
    "        xv = repeat_kv(xv,self.n_rep)\n",
    "         # 将头作为批次维度处理，(bsz批次大小, seqlen序列长度, n_local_heads本地注意力头数, head_dim每个注意力头的维度)--->(bsz, n_local_heads, seqlen, head_dim)\n",
    "        xq = xq.transpose(1,2)\n",
    "        xk = xk.transpose(1,2)\n",
    "        xv = xv.transpose(1,2)\n",
    "         # 根据是否⽀持Flash Attention，选择实现⽅式\n",
    "        if self.flash:\n",
    "            # 使⽤Flash Attention\n",
    "            output = torch.nn.functional.scaled_dot_product_attention(xq,xk,xv,attn_mask=None,\n",
    "                    dropout_p=self.dropout if self.training else 0.0,is_causal = True)\n",
    "        else: # 使⽤⼿动实现的注意⼒机制。\n",
    "            scores = troch.matmul(xq,xk.transpose(2,3))/math.sqrt(self.head_dim)\n",
    "            assert hasattr(self,'mask')\n",
    "            scores = scores + self.mask[:,:,:seqlen,:seqlen]\n",
    "            scores = F.softmax(scores,float(),dim=-1).type_as(xq)\n",
    "            scores = self.attn_dropout(scores)\n",
    "            output = torch.matmul(scores,xv)\n",
    "        # 恢复时间维度并合并头\n",
    "        output = output.transpose(1,2).contiguous().view(bsz,seqlen,-1)\n",
    "         # 最终投影回残差流\n",
    "        output = self.wo(output)\n",
    "        output = self.resid_dropout(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "919c1240-48bc-4413-81c0-44b4f1521eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 50, 768])\n"
     ]
    }
   ],
   "source": [
    "# 创建Attention实例\n",
    "attention_model = Attention(args)\n",
    "\n",
    "# 模拟输入数据\n",
    "batch_size = 1\n",
    "seq_len = 50  # 假设实际使用的序列长度为50\n",
    "dim = args.dim\n",
    "x = torch.rand(batch_size, seq_len, dim)  # 随机生成输入张量\n",
    "# freqs_cos = torch.rand(seq_len, dim // 2)  # 模拟cos频率，用于RoPE\n",
    "# freqs_sin = torch.rand(seq_len, dim // 2)  # 模拟sin频率，用于RoPE\n",
    "\n",
    "freqs_cos, freqs_sin = precompute_freqs_cis(dim//args.n_heads, seq_len)\n",
    "\n",
    "# 运行Attention模型\n",
    "output = attention_model(x, freqs_cos, freqs_sin)\n",
    "\n",
    "# attention出来之后的形状 依然是[batch_size, seq_len, dim]\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8460ae-98de-4b78-9b1a-4a71f6f18e52",
   "metadata": {},
   "source": [
    "##  构建LLaMA2 MLP（Multi-Layer Perceptron）模块----线性变换层和一个激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9521a43-e33d-45ac-8608-0ccd0bfb36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self , dim:int , hidden_dim:int , multiple_of:int , dropout:float):\n",
    "        super().__init__()\n",
    "        if hidden_dim is None:\n",
    "            # 如果没有指定隐藏层的维度，我们将其设置为输⼊维度的4倍\n",
    "            hidden_dim = 4*dim\n",
    "             # 然后将其减少到2/3\n",
    "            hidden_dim = int(2*hidden_dim/3)\n",
    "            #确保它是multiple_of的倍数\n",
    "            hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1)//multiple_of)\n",
    "        # 定义第⼀层线性变换，从输⼊维度到隐藏维度\n",
    "        self.w1 = nn.Linear(dim,hidden_dim,bias=False)\n",
    "        # 定义第⼆层线性变换，从隐藏维度到输⼊维度\n",
    "        self.w2 = nn.Linear(hidden_dim,dim,bias=False)\n",
    "        # 定义第三层线性变换，从输⼊维度到隐藏维度\n",
    "        self.w3 = nn.Linear(dim,hidden_dim,bias=False)\n",
    "         # 定义dropout层，⽤于防⽌过拟合\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # F.silu 是激活函数，公式为silu(x) = x * sigmoid(x)；self.dropout (...)：随机丢弃，正则化，维度不变\n",
    "    def forward(self,x):\n",
    "         # 前向传播函数\n",
    "        # ⾸先，输⼊x通过第⼀层线性变换和SILU激活函数\n",
    "        # 然后，结果乘以输⼊x通过第三层线性变换的结果\n",
    "        # 最后，通过第⼆层线性变换和dropout层\n",
    "        return self.dropout(      self.w2(     F.silu(self.w1(x)) * self.w3(x)    )     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fdf95d4-15d7-48d5-9e14-9a9ba07c1545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1903, -0.0837,  0.0198,  ..., -0.0112, -0.1498,  0.0918],\n",
       "          [-0.0385, -0.0892, -0.1282,  ...,  0.1547, -0.1080,  0.0659],\n",
       "          [-0.0009, -0.1448, -0.1081,  ..., -0.0095, -0.0075,  0.2419],\n",
       "          ...,\n",
       "          [ 0.0301,  0.0385,  0.0852,  ..., -0.1626,  0.2265,  0.0170],\n",
       "          [-0.1769,  0.0666, -0.0467,  ...,  0.0284,  0.0935,  0.0332],\n",
       "          [-0.0431,  0.1322, -0.0535,  ...,  0.0838,  0.0649,  0.0841]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " torch.Size([1, 50, 768]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建实例mlp\n",
    "mlp = MLP(args.dim,args.hidden_dim,args.multiple_of,args.dropout)\n",
    "x = torch.randn(1,50,args.dim)\n",
    "output = mlp(x)\n",
    "output,output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be5a6d-f60e-4598-adfe-0d9faca5206b",
   "metadata": {},
   "source": [
    "##  构建 LLaMA2 Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2da083f8-0f68-452a-8679-0bd47db337ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,layer_id:int,args:ModelConfig):\n",
    "        super().__init__()\n",
    "         # 定义多头注意⼒的头数\n",
    "        self.n_heads = args.n_heads\n",
    "         # 定义输⼊维度\n",
    "        self.dim = args.dim\n",
    "        # 定义每个头的维度，等于输⼊维度除以头数\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        # 定义LLaMA2Attention对象，⽤于进⾏多头注意⼒计算\n",
    "        self.attention = Attention(args)\n",
    "         # 定义LLaMA  MLP对象，⽤于进⾏前馈神经⽹络计算\n",
    "        self.feed_forward = MLP(\n",
    "            dim =args.dim,\n",
    "            hidden_dim =args.hidden_dim,\n",
    "            multiple_of = args.multiple_of,\n",
    "            dropout = args.dropout,\n",
    "        )\n",
    "        # 定义层的ID，当前解码器层在整个模型中的编号（索引）\n",
    "        self.layer_id = layer_id\n",
    "         # 定义注意⼒计算的归⼀化层\n",
    "        self.attention_norm = RMSNorm(args.dim, eps = args.norm_eps)\n",
    "         # 定义前馈神经⽹络计算的归⼀化层\n",
    "        self.ffn_norm = RMSNorm(args.dim , eps = args.norm_eps)\n",
    "        \n",
    "    def forward(self,x,freqs_cos,freqs_sin): # 前向传播函数\n",
    "         # ⾸先，输⼊x经过注意⼒归⼀化层，然后进⾏注意⼒计算，结果与输⼊x相加得到h\n",
    "        h = x + self.attention.forward( self.attention_norm(x),freqs_cos,freqs_sin )\n",
    "        # h经过前馈神经⽹络归⼀化层，然后进⾏前馈神经⽹络计算，结果与h相加得到输出\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5257eef1-ae87-41a7-bf85-cb67c683048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.7873,  0.3936, -0.7192,  ..., -0.0743,  1.2577, -0.3635],\n",
       "          [ 0.5187, -0.5349, -0.2202,  ..., -1.5718, -0.2472, -0.1420],\n",
       "          [ 0.2706, -0.2408, -1.0117,  ...,  0.0044, -0.6116, -0.0244],\n",
       "          ...,\n",
       "          [ 0.6035, -0.7309, -1.8942,  ...,  0.2627,  0.4336, -1.3416],\n",
       "          [ 1.0965, -2.1346,  1.3750,  ...,  0.1465,  0.5675,  0.9712],\n",
       "          [-1.5775,  0.3258, -1.3788,  ..., -0.1122, -0.8187,  0.8832]]]),\n",
       " torch.Size([1, 50, 768]),\n",
       " tensor([[[-1.0137,  0.6413, -0.2364,  ..., -0.3789,  0.9855, -0.1646],\n",
       "          [ 0.2198, -0.5613, -0.1305,  ..., -1.5832, -0.2571, -0.0605],\n",
       "          [-0.0999, -0.2659, -1.2229,  ...,  0.0981, -0.5334,  0.1146],\n",
       "          ...,\n",
       "          [ 0.5414, -0.8398, -1.8394,  ...,  0.4887,  0.4185, -1.3680],\n",
       "          [ 1.1526, -2.0901,  1.4264,  ...,  0.0723,  0.4947,  1.2367],\n",
       "          [-1.6481,  0.1264, -1.4654,  ..., -0.1283, -0.9463,  0.9406]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " torch.Size([1, 50, 768]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##DecoderLayer实例\n",
    "decoderlayer = DecoderLayer(0,args)#0为layer_id:int\n",
    "dim = args.dim\n",
    "seq_len = 50\n",
    "x = torch.randn(1,seq_len,dim)\n",
    "freqs_cos ,freqs_sin = precompute_freqs_cis(dim//args.n_heads,seq_len)\n",
    "out = decoderlayer(x,freqs_cos,freqs_sin)\n",
    "x,x.shape,out,out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f6b24-d13a-4e19-9fdf-7e154b50a2a4",
   "metadata": {},
   "source": [
    "##  构建LLaMA2模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09b61b86-ff11-47a4-8391-94f712484dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch._utils import _cuda\n",
    "except ImportError:\n",
    "    mock_cuda = MagicMock()\n",
    "    sys.modules['torch._utils._cuda'] = mock_cuda\n",
    "    import torch._utils\n",
    "    torch._utils._cuda = mock_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f07ac78-8439-4c6a-9b8f-6f2273dbdff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(PreTrainedModel):\n",
    "    config_class = ModelConfig #模型的词汇表、嵌入维度等参数类\n",
    "    last_loss : Optional[torch.Tensor]# 记录最后⼀次计算的损失\n",
    "\n",
    "        # 1.9.1 初始化权重的函数\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance (module,nn.Linear):#线性层\n",
    "            #均值为 0、标准差为 0.02 的标准正态分布随机初始化\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:#偏置如果存在，初始化为全 0\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module,nn.Embedding):#嵌入层\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0 ,std = 0.02)\n",
    "    \n",
    "    #第一部分：模型初始化\n",
    "    #1.1 继承类，保存配置\n",
    "    def __init__(self, args:ModelConfig = None):\n",
    "        super().__init__(args)\n",
    "        self.args = args\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.n_layers = args.n_layers\n",
    "    #1.2 词嵌入层，将tokenID转化为向量   \n",
    "        self.tok_embeddings = nn.Embedding(args.vocab_size,args.dim)\n",
    "    #1.3 dropout层，作用于词嵌入后的张量，随机将最后一维的维特征中X%的位置置为 0，防止过拟合\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "    #1.4 解码器层列表（layers）    \n",
    "        self.layers = torch.nn.ModuleList()#ModuleList[用于存储和管理神经网络模块]中存储n_layers个 DecoderLayer实例\n",
    "        for layer_id in range(args.n_layers):# 循环n_layers次\n",
    "            self.layers.append(DecoderLayer(layer_id,args)) # 加入n_layers个解码器层\n",
    "    #1.5 归一化层        \n",
    "        self.norm = RMSNorm(args.dim, eps = args.norm_eps)\n",
    "    #1.6 输出层（output）：把向量映射回词汇表    \n",
    "        self.output = nn.Linear(args.dim, args.vocab_size, bias = False)\n",
    "    #1.7 共享词嵌入和输出层的权重：减少参数\n",
    "        self.tok_embeddings.weight = self.output.weight\n",
    "    #1.8 预计算RoPE--旋转位置编码\n",
    "        freqs_cos, freqs_sin = precompute_freqs_cis(self.args.dim // self.args.n_heads, self.args.max_seq_len)\n",
    "        # register_buffer表示这些张量不是模型参数（不会被梯度更新）\n",
    "        # persistent=False表示保存模型时不保存这些张量\n",
    "        self.register_buffer(\"freqs_cos\" ,freqs_cos,persistent = False)\n",
    "        self.register_buffer(\"freqs_sin\",freqs_sin,persistent =False)\n",
    "    #1.9 参数初始化：给权重赋初始值\n",
    "        self.apply(self._init_weights)# 遍历所有层，调用_init_weights\n",
    "        for pn,p in self.named_parameters():\n",
    "            # 对特定参数进行精细初始化\n",
    "            # 对前馈网络的参数（w3/wo）按层数调整标准差，避免深层模型的梯度爆炸\n",
    "            if pn.endswith('w3.weight') or pn.endswith('wo.weight'):\n",
    "                torch.nn.init.normal_(p, mean =0.0, std=0.02/math.sqrt(2*args.n_layers))\n",
    "    #1.10 初始化最后⼀次前向传播的损失属性\n",
    "        self.last_loss = None # 存储最新的损失值\n",
    "        self.OUT = CausalLMOutputWithPast() # 封装模型输出（logits和loss）\n",
    "        self._no_split_modules = [name for name , _ in self.named_modules()] # 不分割的模块列表\n",
    "\n",
    "            \n",
    "    #第二部分：前向传播\n",
    "    #2.1 输入 token ID--tok_embeddings转为语义特征向量--dropouts随机失活--截取对应序列长度的旋转位置编码--\n",
    "     #   遍历所有DecoderLayer---\n",
    "     #   归一化（把h的数值缩放到合理范围，保证后续计算的稳定性（避免梯度消失 / 爆炸），但不会改变其 “语义特征向量” 的本质）\n",
    "     #   --output层：将特征向量映射为词汇表维度的原始得分（logits）\n",
    "     #  分支处理：若有目标值（训练阶段），计算交叉熵损失；若无目标值（推理阶段），仅取最后一个token的logits →\n",
    "     #  封装logits和loss到OUT对象中返回\n",
    "    def forward(self, tokens:torch.Tensor,targets:Optional[torch.Tensor]=None, **keyargs) ->torch.Tensor:\n",
    "        if 'input_ids' in keyargs:\n",
    "            tokens = keyargs['input_ids']\n",
    "        if 'attention_mask' in keyargs:\n",
    "            targets = keyargs['attention_mask']\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        h = self.dropout(h)\n",
    "        freqs_cos = self.freqs_cos[:seqlen]\n",
    "        freqs_sin = self.freqs_sin[:seqlen]\n",
    "        for layer in self.layers:\n",
    "            h = layer(h,freqs_cos,freqs_sin)\n",
    "        h = self.norm(h)\n",
    "        if targets is not None:\n",
    "            logits = self.output(h)\n",
    "            #计算交叉熵损失\n",
    "            self.last_loss = F.cross_entropy(logits.view(-1,logits.size(-1)),\n",
    "                                            targets.view(-1),ignore_index=0,\n",
    "                                            reduction='none')\n",
    "        else:\n",
    "            #推理阶段，只需要预测下一个 token，所以只取最后一个 token 的向量进行映射\n",
    "            logits = self.output(h[:,[-1],:])\n",
    "            self.last_loss = None\n",
    "        \n",
    "        self.OUT.__setitem__('logits',logits)\n",
    "        self.OUT.__setitem__('last_loss',self.last_loss)\n",
    "        return self.OUT\n",
    "        \n",
    "    #第三部分：文本生成--一个循环过程，每次用当前的 token ID 序列作为输入，通过模型前向传播得到预测的 logits（得分），再从 logits 中采样出下一个 token ID，拼接到原序列后重复此过程，直到满足停止条件    \n",
    "    @torch.inference_mode()#@torch.inference_mode()装饰器会关闭梯度计算，加快推理速度\n",
    "    #idx--用户提供的初始 token ID 序列；\n",
    "    #temperature--控制生成的随机性：值越大，随机性越强；值为 0 时是贪心采样（选得分最高的 token）\n",
    "    #Top-K 采样的参数：只保留得分最高的k个 token 作为候选，其余排除；为None时不启用 Top-K\n",
    "    def generate(self, idx, stop_id=None, max_new_tokens=256, temperature=1.0, top_k=None):\n",
    "        index = idx.shape[1]\n",
    "        for _ in range(max_new_tokens):\n",
    "            #判断输入序列长度是否超过模型的max_seq_len-->序列截断\n",
    "            idx_cond = idx if idx.size(1) <= self.args.max_seq_len else idx[:,-self.args.max_seq_len:]\n",
    "            # 前向传播获取logits\n",
    "            # self(idx_cond)——模型实例被调用，执行forward方法，返回的是模型的输出对象--self.OUT\n",
    "            # .logits—— 从输出对象中提取 logits（预测得分）\n",
    "            logits = self(idx_cond).logits\n",
    "            logits = logits[:,-1,:]#提取最后一个 token 的 logits\n",
    "            if temperature == 0.0:#贪心采样，生成的文本最 “通顺” 但缺乏多样性\n",
    "                _,idx_next = torch.topk(logits, k=1, dim=-1)#选得分最高的 token\n",
    "            else :#带温度的随机采样\n",
    "                logits = logits / temperature#调整 logits 的分布，控制随机性\n",
    "                if top_k is not None:\n",
    "                    #取张量指定维度上前 k 个最大值，返回值（v）和对应的索引（idx）\n",
    "                    v,_ = torch.topk(logits,min(top_k,logits.size(-1)))\n",
    "                    #废掉所有低于阈值的 token；v[:,[-1]] → 取出 k 个最高分中的 “最低分”（阈值）\n",
    "                    logits[logits<v[:,[-1]]] = -float('Inf')\n",
    "                #按概率选一个token\n",
    "                #将得分转换为概率\n",
    "                probs = F.softmax(logits, dim=-1)#对调整后的 logits 在最后一个维度（词汇表维度）做 softmax 归一化，转换为概率分布（所有值之和为 1）\n",
    "                #从概率分布probs中随机采样 1 个样本（即下一个 token ID）\n",
    "                idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            #如果采样到的下一个 token ID 是停止符（stop_id）（比如句号、<EOS>标记），立即跳出循环，停止生成\n",
    "            if idx_next == stop_id:\n",
    "                break\n",
    "            idx = torch.cat((idx,idx_next),dim=1)\n",
    "        return idx[:,index:]#只返回生成的新 token，去掉初始输入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "686391c9-34dd-4814-8256-c8f002e6ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 82594560\n",
      "torch.Size([1, 1, 6144])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(0, 6144, (1, 50)) # [bs, seq_len]\n",
    "# 实例化LLaMA2Model\n",
    "model = Transformer(args=args)\n",
    "# 计算model的全部参数\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print('Number of parameters:', num_params)\n",
    "out = model(x)\n",
    "print(out.logits.shape) # [batch_size, 1, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3ed48d6-2b2f-44a1-bd20-6a4e1864ade5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 752, 5951, 3313, 2801, 4074,  135, 5020, 5110, 5147, 3141, 4235, 5707,\n",
       "          4619, 4474, 1940, 4055, 1446,  947, 2796, 3119, 1931, 4872,  817, 2554,\n",
       "          1176, 3222, 2920, 5790, 5037,  182, 1659,   69, 1102, 1000, 6019,   58,\n",
       "          5459, 1518,  594,  543, 2836, 1351, 1365, 4381, 5158, 1229,  846,  421,\n",
       "          5957,  820]]),\n",
       " Transformer(\n",
       "   (tok_embeddings): Embedding(6144, 768)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       "   (layers): ModuleList(\n",
       "     (0-11): 12 x DecoderLayer(\n",
       "       (attention): Attention(\n",
       "         (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "         (wk): Linear(in_features=768, out_features=384, bias=False)\n",
       "         (wv): Linear(in_features=768, out_features=384, bias=False)\n",
       "         (wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "         (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "         (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (feed_forward): MLP(\n",
       "         (w1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "         (w2): Linear(in_features=2048, out_features=768, bias=False)\n",
       "         (w3): Linear(in_features=768, out_features=2048, bias=False)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (attention_norm): RMSNorm()\n",
       "       (ffn_norm): RMSNorm()\n",
       "     )\n",
       "   )\n",
       "   (norm): RMSNorm()\n",
       "   (output): Linear(in_features=768, out_features=6144, bias=False)\n",
       " ))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109b666-afe8-43fd-9ad0-cee61ec84f4f",
   "metadata": {},
   "source": [
    "# 训练Tokenizer--BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bebb8ce-9aff-4790-9fb2-caf365b001f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#⽤于加载训练数据和和加载训练完成后的 Tokenizer\n",
    "#pip install tokenizers datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "933f071f-840c-464c-af07-5439ed79eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "导入成功，无报错！\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer ,PreTrainedTokenizerFast\n",
    "from tokenizers import (\n",
    "     decoders,models,pre_tokenizers,trainers,Tokenizer,)\n",
    "from tokenizers.normalizers import NFKC\n",
    "from typing import Generator\n",
    "print(\"导入成功，无报错！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274fcbd-aeb4-4fc5-9658-293e601c06e2",
   "metadata": {},
   "source": [
    "## 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e493362a-32c0-4fe5-bd25-0f69e6c41692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从JSONL格式的文件中逐行读取数据，提取每一行中text字段的内容并返回\n",
    "def read_texts_from_jsonl(file_path:str)->Generator[str,None,None]:\n",
    "    with open(file_path, 'r', encoding = 'utf-8') as f:\n",
    "        for line_num, line in enumerate(f,1):#line_num：当前行的行号，line：当前行的字符串内容\n",
    "            try:\n",
    "                data = json.loads(line)  #json.loads(line)：将单行字符串解析为 JSON 对象（字典类型）\n",
    "                if 'text' not in data:\n",
    "                    raise KeyError(f\"Missing 'text' field in line {line_num}\")\n",
    "                yield data['text']   #将当前行的text字段内容返回给迭代器。此时函数会暂停执行，直到下一次迭代时继续处理下一行\n",
    "            except json.JSONDecodeError:  #捕获JSON解析错误（如行内容格式错误、缺少引号等）\n",
    "                print(f\"Error decoding JSON in line {line_num}\")\n",
    "                continue  #报错后，跳过当前行，继续处理下一行\n",
    "            except KeyError as e:\n",
    "                print (e)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f88e4-3db3-4f85-852d-fe5fde710021",
   "metadata": {},
   "source": [
    "## 创建配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5135cce6-51e4-477e-96a2-cb9341d5d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成配置文件，--使得训练后的 BPE Tokenizer 与 Hugging Face 生态兼容\n",
    "\n",
    "def create_tokenizer_config(save_dir: str)->None: #指定两个配置文件的保存目录save_dir\n",
    "    # 定义分词器的核心配置字典\n",
    "    #构建tokenizer_config字典并保存为tokenizer_config.json\n",
    "    config = {\n",
    "        \"add_bos_token\":False, #分词时 不在 文本开头添加bos_token（<|im_start|>），因为是聊天场景\n",
    "        \"add_eos_token\":False, #分词时 不在 文本结束添加bos_token（<|im_end|>）\n",
    "        \"add_prefix_space\":False, # 不在 文本前添加空格（针对某些子词分词器的兼容设置）\n",
    "        \"bos_token\":\"<|im_start|>\",  # 自定义的开始标记（用于聊天场景的消息开头，如<|im_start|>user）\n",
    "        \"eos_token\":\"<|im_end|>\", # 自定义的结束标记（用于聊天场景的消息结尾）\n",
    "        \"pad_token\":\"<|im_end|>\", #填充标记\n",
    "        \"unk_token\":\"<unk>\",  # UNK（Unknown）token：未知字符标记（遇到分词器不认识的字符时使用）\n",
    "        \"model_max_length\": 1000000000000000019884624838656, #分词器支持的最大序列长度--分词后生成的 token ID的长度-- token 数量\n",
    "        \"clean_up_tokenization_spaces\":False, #不 自动清理分词后的多余空格\n",
    "        \"tokenizer_class\":\"PreTrainedTokenizerFast\", #指定分词器类为快速分词器\n",
    "         # 聊天模板（Jinja2语法）：用于格式化多轮对话数据\n",
    "        \"chat_template\":(  \n",
    "            #{%...%}控制流函数，{{ ... }}把变量的值输出成文本\n",
    "            \"{% for message in messages %}\"\n",
    "            \"{% if message['role'] == 'system' %}\"\n",
    "            \"<|im_start|>system\\n{{message['content']}}<|im_end|>\\n\"\n",
    "            \"{% elif message['role'] == 'user' %}\"\n",
    "            \"<|im_start|>user\\n {{message['content']}}<|im_end|>\\n\"\n",
    "            \"{% elif message['role'] == 'assistant' %}\"\n",
    "            \"<|im_start|>assistant\\n{{message['content']}}<|im_send|>\\n\"\n",
    "            \"{% endif %}\"\n",
    "            \"{% endfor %}\"\n",
    "            #添加生成提示\n",
    "            \"{% if ass_generation_prompt %}\"\n",
    "            \"{{'<|im_start|>assistant\\n'}}\"\n",
    "            \"{% endif %}\"\n",
    "        )\n",
    "    }\n",
    "    # 将config字典写入tokenizer_config.json文件\n",
    "    with open(os.path.join(save_dir,\"tokenizer_config.json\"),\"w\",encoding='utf-8') as f:\n",
    "        json.dump(config, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    # 构建special_tokens_map字典\n",
    "    special_tokens_map = {\n",
    "        \"bos_token\":\"<|im_start|>\", # BOS token映射\n",
    "        \"eos_token\":\"<|im_end|>\",\n",
    "        \"unk_token\":\"<unk>\",\n",
    "        \"pad_token\":\"<|im_end|>\",\n",
    "        \"additional_special_tokens\":[\"<s>\",\"</s>\"]# 额外的特殊token（供分词器识别，不与上述冲突）\n",
    "    }\n",
    "    with open(os.path.join(save_dir,\"special_tokens_map.json\"),\"w\",encoding='utf-8') as f:\n",
    "        json.dump(special_tokens_map,f,ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be620827-643d-4c4b-86bf-a99cc0a2611e",
   "metadata": {},
   "source": [
    "## 训练BPE Tokenizer--分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2693ec31-9eff-4ea3-871a-e5a15c8c5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "##初始化 BPE 分词器并配置各项预处理 / 后处理规则；\n",
    "##从 JSONL 格式的语料文件中读取文本（调用【2.1加载训练数据】的read_texts_from_jsonl生成器）\n",
    "##用 BPE 算法训练分词器，生成指定大小的词汇表；\n",
    "##验证特殊 token 的 ID 是否符合预期；\n",
    "##保存分词器文件，并调用【2.2创建配置文件】create_tokenizer_config生成适配transformers库的配置文件；\n",
    "##最终让训练后的分词器既能用tokenizers库快速处理文本，又能接入transformers生态进行模型训练 / 推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1e615f7-f34c-4614-adac-7162663a3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tokenizer(data_path: str, save_dir: str, vocab_size: int = 8192) -> None:\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    #创建一个 “空的” BPE 分词器。设置未知 token 为<unk>\n",
    "    tokenizer = Tokenizer(model.BPE(unk_token=\"<unk>\"))\n",
    "    #将文本中的字符转换为统一的标准形式，减少词汇表的冗余\n",
    "    tokenizer.normalizer = NFKC()\n",
    "    #对文本进行初步拆分。按UTF-8 字节拆分；add_prefix_space = False不在【中文】文本开头添加前缀空格\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space = False)\n",
    "    #解码器，将分词后的 token 序列还原为原始文本\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "    # 定义特殊 token \n",
    "    special_tokens = [\"<unk>\",\"<s>\",\"</s>\",\"<|im_start|>\",\"<|im_end|>\" ]\n",
    "    # 初始化BPE训练器\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size = vocab_size,\n",
    "        special_tokens = special_tokens,\n",
    "        min_frequency = 2,#将数据集中出现次数≥min_frequency的相邻字节/子词对，合并成一个新的单一符号（新子词），并加入词汇表的操作\n",
    "        show_progress = True, # 显示训练进度条（直观看到训练过程）\n",
    "        initial_alphabet = pre_tokenizers.ByteLevel.alphabet() # 初始字母表\n",
    "    )\n",
    "    print(f\"Training tokenizer with data from {data_path}\")\n",
    "\n",
    "    ###！读取语料并训练分词器！\n",
    "    # 调用生成器函数，读取JSONL中的文本（惰性迭代，节省内存）\n",
    "    texts = read_texts_from_jsonl(data_path)\n",
    "    # 从BPE迭代器训练分词器\n",
    "    tokenizer.train_from_iterator(texts, trainer = trainer, length = os.path.getsize(data_path))\n",
    "    #验证特殊 token 的 ID\n",
    "    try:\n",
    "        assert tokenizer.token_to_id(\"<unk>\") == 0\n",
    "        assert tokenizer.token_to_id(\"<s>\") == 1\n",
    "        assert tokenizer.token_to_id(\"</s>\") == 2\n",
    "        assert tokenizer.token_to_id(\"<|im_start|>\") == 3\n",
    "        assert tokenizer.token_to_id(\"<|im_end|>\") == 4\n",
    "    except AssertionError as e:\n",
    "        print(\"Special tokens mapping error:\",e)\n",
    "        raise\n",
    "    # 保存分词器并生成配置文件\n",
    "     #tokenizer.json：是tokenizers库的标准输出文件，包含分词器的所有【规则】（BPE 模型、词汇表、归一化器、预分词器等），可以直接用tokenizers.Tokenizer.from_file加载\n",
    "    tokenizer.save(os.path.join(save_dir,\"tokenizer.json\"))\n",
    "     #生成tokenizer_config.json和special_tokens_map.json，让训练后的分词器能被transformers.AutoTokenizer.from_pretrained加载\n",
    "    create_tokenizer_config(save_dir)\n",
    "    print(f\"Tokenizer save to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c0d8d-7e29-4051-be89-26783402e632",
   "metadata": {},
   "source": [
    "## 使用训练完成的Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c1a26e7-87f5-4dfa-9fe7-696a02e615ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证分词器是否能正常工作\n",
    "def eval_tokenizer(tokenizer_path:str) ->None:\n",
    "    try :\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer : {e}\")\n",
    "        return\n",
    "    print(\"\\n=== Tokenizer基本信息 ===\")\n",
    "    print(f\"Vocab size: {len(tokenizer)}\")\n",
    "    print(f\"Special tokens: {tokenizer.all_special_tokens}\")\n",
    "    print(f\"Special token IDs: {tokenizer.all_special_ids}\")\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"你是一个AI助手。\"},\n",
    "        {\"role\":\"user\",\"content\":\"How are you?\"},\n",
    "        {\"role\":\"assistant\",\"content\":\"I'm fine,thank you. and you ?\"},\n",
    "        {\"role\":\"user\",\"content\":\"I'm good too.\"},\n",
    "        {\"role\":\"assistant\",\"content\":\"That's great to hear!\"},\n",
    "    ]\n",
    "    print(\"\\n====聊天模板测试===\")\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,tokenize = False,\n",
    "        #add_generation_prompt = True\n",
    "    )\n",
    "    print(\"Generated prompt:\\n\",prompt,sep=\"\")\n",
    "    print(\"\\n====编码解码测试===\")\n",
    "    encoded = tokenizer(prompt, truncation = True, max_length = 256)\n",
    "    decoded = tokenizer.decode(encoded[\"input_ids\"], skip_special_tokens = False)\n",
    "    print(\"Decoded text matches original :\",decoded == prompt)\n",
    "    print(\"\\n====特殊token处理 ===\")\n",
    "    test_text = \"<|im_start|>user\\nHello<|im_end|>\"\n",
    "    encoded = tokenizer(test_text).input_ids\n",
    "    decoded = tokenizer.decode(encoded)\n",
    "    print(f\"Original : {test_text}\")\n",
    "    print(f\"Decoded : {decoded}\")\n",
    "    print(\"Special tokens preserved : \",decoded == test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce94a7-6cbe-4866-a5bc-d8ec0f44383e",
   "metadata": {},
   "source": [
    "## 下载和处理好的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db81469a-fde6-44eb-b910-7df9e98e39d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tokenizer基本信息 ===\n",
      "Vocab size: 6144\n",
      "Special tokens: ['<|im_start|>', '<|im_end|>', '<unk>', '<s>', '</s>']\n",
      "Special token IDs: [3, 4, 0, 1, 2]\n",
      "\n",
      "====聊天模板测试===\n",
      "Generated prompt:\n",
      "<|im_start|>system\n",
      "你是一个AI助手。<|im_end|>\n",
      "<|im_start|>user\n",
      "How are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "I'm fine,thank you. and you ?<|im_end|>\n",
      "<|im_start|>user\n",
      "I'm good too.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "That's great to hear!<|im_end|>\n",
      "\n",
      "\n",
      "====编码解码测试===\n",
      "Decoded text matches original : True\n",
      "\n",
      "====特殊token处理 ===\n",
      "Original : <|im_start|>user\n",
      "Hello<|im_end|>\n",
      "Decoded : <|im_start|>user\n",
      "Hello<|im_end|>\n",
      "Special tokens preserved :  True\n"
     ]
    }
   ],
   "source": [
    "eval_tokenizer(r\"C:\\Users\\xuexu\\NLP_LLM\\Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b48cbc-878c-4663-9e27-72a4a512ca47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (torchvision)",
   "language": "python",
   "name": "python310_torchvision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
